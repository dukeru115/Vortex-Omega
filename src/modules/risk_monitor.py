"""
RiskMonitor for NFCS - Critical Safety Component
===============================================

High-performance risk monitoring system with hysteresis, trend analysis
and resonance bus integration. Provides early threat detection and
automatic escalation of critical states.

Key Capabilities:
- Monitor Ha, œÅ_def_mean, R_field, R_mod with configurable thresholds
- Hysteresis analysis to prevent false positives
- Derivative analysis (trends) on sliding windows
- Threat classification: NORMAL, WARNING, CRITICAL, EMERGENCY
- Automatic publication to resonance bus
- Detailed logging and telemetry
"""

import logging
import time
import threading
from collections import deque
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple
import numpy as np

from ..core.state import RiskMetrics
from ..orchestrator.resonance_bus import (
    get_global_bus,
    publish_risk_metrics,
    publish_emergency,
    RiskMetricsPayload,
    TopicType,
    EventPriority,
)


class RiskLevel(Enum):
    """Risk levels in the system"""

    NORMAL = "NORMAL"
    WARNING = "WARNING"
    CRITICAL = "CRITICAL"
    EMERGENCY = "EMERGENCY"


class TrendDirection(Enum):
    """Direction of metric trend"""

    INCREASING = "INCREASING"
    DECREASING = "DECREASING"
    STABLE = "STABLE"
    OSCILLATING = "OSCILLATING"


@dataclass
class RiskThresholds:
    """Risk thresholds with hysteresis"""

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –≤—Ö–æ–¥–∞ –≤ state —Ä–∏—Å–∫–∞
    ha_warning: float = 0.6
    ha_critical: float = 0.8
    ha_emergency: float = 0.95

    defect_warning: float = 0.05
    defect_critical: float = 0.1
    defect_emergency: float = 0.2

    coherence_global_warning: float = 0.4
    coherence_global_critical: float = 0.3
    coherence_global_emergency: float = 0.2

    coherence_modular_warning: float = 0.5
    coherence_modular_critical: float = 0.3
    coherence_modular_emergency: float = 0.2

    # –ì–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–Ω—ã–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å < 1.0)
    warning_exit_factor: float = 0.85  # -15% –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ WARNING
    critical_exit_factor: float = 0.75  # -25% –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ CRITICAL
    emergency_exit_factor: float = 0.7  # -30% –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ EMERGENCY

    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö (—Ç—Ä–µ–Ω–¥-–∞–Ω–∞–ª–∏–∑)
    derivative_warning_threshold: float = 0.05  # –ó–∞ —à–∞–≥
    derivative_critical_threshold: float = 0.1  # –ó–∞ —à–∞–≥

    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π –¥–ª—è —ç—Å–∫–∞–ª–∞—Ü–∏–∏
    violations_warning_threshold: int = 3
    violations_critical_threshold: int = 10
    violations_emergency_threshold: int = 25


@dataclass
class MetricHistory:
    """History of metric values for trend analysis"""

    values: deque = field(default_factory=lambda: deque(maxlen=50))
    timestamps: deque = field(default_factory=lambda: deque(maxlen=50))
    window_size: int = 10

    def add_value(self, value: float, timestamp: float = None):
        """Add value to history"""
        if timestamp is None:
            timestamp = time.time()

        self.values.append(value)
        self.timestamps.append(timestamp)

    def get_recent_values(self, count: int = None) -> List[float]:
        """Get recent values"""
        if count is None:
            count = self.window_size
        return list(self.values)[-count:]

    def get_derivative(self) -> float:
        """Calculate derivative (trend) for recent values"""
        if len(self.values) < 2:
            return 0.0

        recent_values = self.get_recent_values()
        recent_times = list(self.timestamps)[-len(recent_values) :]

        if len(recent_values) < 2:
            return 0.0

        # –ü—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
        n = len(recent_values)
        sum_t = sum(recent_times)
        sum_v = sum(recent_values)
        sum_tv = sum(t * v for t, v in zip(recent_times, recent_values))
        sum_t2 = sum(t * t for t in recent_times)

        denominator = n * sum_t2 - sum_t * sum_t
        if abs(denominator) < 1e-10:
            return 0.0

        slope = (n * sum_tv - sum_t * sum_v) / denominator
        return slope

    def get_trend_direction(self) -> TrendDirection:
        """Determine trend direction"""
        derivative = self.get_derivative()
        abs_derivative = abs(derivative)

        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
        stable_threshold = 1e-6
        oscillation_threshold = 0.01

        if abs_derivative < stable_threshold:
            return TrendDirection.STABLE

        # Check –Ω–∞ –æ—Å—Ü–∏–ª–ª—è—Ü–∏–∏
        if len(self.values) >= 4:
            recent = self.get_recent_values(4)
            direction_changes = 0
            for i in range(1, len(recent) - 1):
                if ((recent[i] > recent[i - 1]) and (recent[i] > recent[i + 1])) or (
                    (recent[i] < recent[i - 1]) and (recent[i] < recent[i + 1])
                ):
                    direction_changes += 1

            if direction_changes >= 2:
                return TrendDirection.OSCILLATING

        return TrendDirection.INCREASING if derivative > 0 else TrendDirection.DECREASING

    def get_volatility(self) -> float:
        """Calculate metric volatility"""
        if len(self.values) < 2:
            return 0.0

        recent_values = self.get_recent_values()
        return float(np.std(recent_values))

    def is_anomaly(self, current_value: float, z_threshold: float = 3.0) -> bool:
        """Anomaly detection via Z-score"""
        if len(self.values) < 5:  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            return False

        recent_values = self.get_recent_values()
        mean_val = np.mean(recent_values)
        std_val = np.std(recent_values)

        if std_val < 1e-10:  # –ù–µ—Ç –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏
            return False

        z_score = abs(current_value - mean_val) / std_val
        return z_score > z_threshold


@dataclass
class RiskAssessment:
    """Risk assessment result"""

    current_level: RiskLevel = RiskLevel.NORMAL
    previous_level: RiskLevel = RiskLevel.NORMAL
    level_changed: bool = False

    # –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
    ha_risk: RiskLevel = RiskLevel.NORMAL
    defect_risk: RiskLevel = RiskLevel.NORMAL
    coherence_global_risk: RiskLevel = RiskLevel.NORMAL
    coherence_modular_risk: RiskLevel = RiskLevel.NORMAL

    # Information –æ —Ç—Ä–µ–Ω–¥–∞—Ö
    ha_trend: TrendDirection = TrendDirection.STABLE
    defect_trend: TrendDirection = TrendDirection.STABLE
    coherence_global_trend: TrendDirection = TrendDirection.STABLE
    coherence_modular_trend: TrendDirection = TrendDirection.STABLE

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è information
    violations_count: int = 0
    anomalies_detected: List[str] = field(default_factory=list)
    risk_factors: List[str] = field(default_factory=list)
    systemic_risk_score: float = 0.0

    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    assessment_time: float = field(default_factory=time.time)

    def get_max_risk_level(self) -> RiskLevel:
        """Get maximum risk level among all metrics"""
        risk_levels = [
            self.ha_risk,
            self.defect_risk,
            self.coherence_global_risk,
            self.coherence_modular_risk,
        ]

        # –ü–æ—Ä—è–¥–æ–∫ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
        level_order = {
            RiskLevel.NORMAL: 0,
            RiskLevel.WARNING: 1,
            RiskLevel.CRITICAL: 2,
            RiskLevel.EMERGENCY: 3,
        }

        max_level = max(risk_levels, key=lambda x: level_order[x])
        return max_level

    def get_risk_summary(self) -> str:
        """Get brief description of risks"""
        if self.current_level == RiskLevel.NORMAL:
            return "System –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏"

        active_risks = []
        if self.ha_risk != RiskLevel.NORMAL:
            active_risks.append(f"Ha:{self.ha_risk.value}")
        if self.defect_risk != RiskLevel.NORMAL:
            active_risks.append(f"Defects:{self.defect_risk.value}")
        if self.coherence_global_risk != RiskLevel.NORMAL:
            active_risks.append(f"R_global:{self.coherence_global_risk.value}")
        if self.coherence_modular_risk != RiskLevel.NORMAL:
            active_risks.append(f"R_modular:{self.coherence_modular_risk.value}")

        return f"–†–∏—Å–∫–∏: {', '.join(active_risks)}"


class RiskMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä —Ä–∏—Å–∫–æ–≤ –¥–ª—è NFCS

    –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è system –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è NFCS
    —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –∞–Ω–æ–º–∞–ª–∏–π, –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–∏—Å–∫–∞–º–∏.
    """

    def __init__(
        self,
        thresholds: Optional[RiskThresholds] = None,
        history_window: int = 50,
        enable_trend_analysis: bool = True,
        enable_anomaly_detection: bool = True,
        enable_auto_publication: bool = True,
    ):

        self.thresholds = thresholds or RiskThresholds()
        self.history_window = history_window
        self.enable_trend_analysis = enable_trend_analysis
        self.enable_anomaly_detection = enable_anomaly_detection
        self.enable_auto_publication = enable_auto_publication

        # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        self.ha_history = MetricHistory()
        self.defect_history = MetricHistory()
        self.coherence_global_history = MetricHistory()
        self.coherence_modular_history = MetricHistory()

        # –¢–µ–∫—É—â–µ–µ state
        self.current_risk_level = RiskLevel.NORMAL
        self.last_assessment: Optional[RiskAssessment] = None
        self.total_violations = 0
        self.consecutive_violations = 0
        self.last_violation_reset = time.time()

        # Thread safety
        self._lock = threading.RLock()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "assessments_count": 0,
            "escalations_count": 0,
            "anomalies_detected": 0,
            "emergency_triggers": 0,
            "avg_assessment_time_ms": 0.0,
            "last_assessment_time": 0.0,
        }

        # –õ–æ–≥–≥–µ—Ä
        self.logger = logging.getLogger(f"{__name__}.RiskMonitor")

        # –†–µ–∑–æ–Ω–∞–Ω—Å–Ω–∞—è —à–∏–Ω–∞
        self.bus = get_global_bus()

        self.logger.info("RiskMonitor initialized")

    def assess_risks(self, risk_metrics: RiskMetrics) -> RiskAssessment:
        """
        –ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤

        Args:
            risk_metrics: –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –∏–∑ —Å–∏—Å—Ç–µ–º—ã

        Returns:
            RiskAssessment: –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–∏—Å–∫–æ–≤
        """
        start_time = time.time()

        with self._lock:
            try:
                # Update –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫
                current_time = time.time()
                self._update_metric_histories(risk_metrics, current_time)

                # Creation –Ω–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏
                assessment = RiskAssessment()
                assessment.previous_level = self.current_risk_level

                # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–µ
                assessment.ha_risk = self._assess_hallucination_risk(
                    risk_metrics.hallucination_number
                )
                assessment.defect_risk = self._assess_defect_risk(risk_metrics.rho_def_mean)
                assessment.coherence_global_risk = self._assess_coherence_global_risk(
                    risk_metrics.coherence_global
                )
                assessment.coherence_modular_risk = self._assess_coherence_modular_risk(
                    risk_metrics.coherence_modular
                )

                # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
                if self.enable_trend_analysis:
                    assessment.ha_trend = self.ha_history.get_trend_direction()
                    assessment.defect_trend = self.defect_history.get_trend_direction()
                    assessment.coherence_global_trend = (
                        self.coherence_global_history.get_trend_direction()
                    )
                    assessment.coherence_modular_trend = (
                        self.coherence_modular_history.get_trend_direction()
                    )

                # –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
                if self.enable_anomaly_detection:
                    assessment.anomalies_detected = self._detect_anomalies(risk_metrics)

                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
                assessment.current_level = assessment.get_max_risk_level()

                # –£—á–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏–π –∏ —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è —ç—Å–∫–∞–ª–∞—Ü–∏–∏
                assessment.current_level = self._apply_escalation_logic(
                    assessment.current_level, assessment
                )

                # Update —Å—á–µ—Ç—á–∏–∫–æ–≤ –Ω–∞—Ä—É—à–µ–Ω–∏–π
                assessment.violations_count = self._update_violation_counters(assessment)

                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Ä–∏—Å–∫–∞
                assessment.systemic_risk_score = self._calculate_systemic_risk(
                    risk_metrics, assessment
                )

                # –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
                assessment.risk_factors = self._identify_risk_factors(assessment, risk_metrics)

                # Check –∏–∑–º–µ–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è
                assessment.level_changed = assessment.current_level != assessment.previous_level

                # Update —Å–æ—Å—Ç–æ—è–Ω–∏—è
                self.current_risk_level = assessment.current_level
                self.last_assessment = assessment

                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è –≤ —à–∏–Ω—É –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞
                if self.enable_auto_publication:
                    self._publish_assessment(assessment, risk_metrics)

                # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                if assessment.level_changed:
                    self.logger.warning(
                        f"–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ –∏–∑–º–µ–Ω–µ–Ω: {assessment.previous_level.value} ‚Üí "
                        f"{assessment.current_level.value}. "
                        f"–ü—Ä–∏—á–∏–Ω—ã: {', '.join(assessment.risk_factors)}"
                    )
                    self.stats["escalations_count"] += 1

                    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —ç—Å–∫–∞–ª–∞—Ü–∏—è
                    if assessment.current_level == RiskLevel.EMERGENCY:
                        self.stats["emergency_triggers"] += 1
                        self._trigger_emergency(assessment, risk_metrics)

                # Update —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                processing_time = (time.time() - start_time) * 1000
                self.stats["assessments_count"] += 1
                self.stats["avg_assessment_time_ms"] = (
                    self.stats["avg_assessment_time_ms"] * 0.9 + processing_time * 0.1
                )
                self.stats["last_assessment_time"] = current_time

                return assessment

            except Exception as e:
                self.logger.error(f"Error –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤: {e}")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Ä–∏—Å–∫–æ–º
                emergency_assessment = RiskAssessment()
                emergency_assessment.current_level = RiskLevel.EMERGENCY
                emergency_assessment.risk_factors = [f"Error –º–æ–Ω–∏—Ç–æ—Ä–∞: {str(e)}"]
                return emergency_assessment

    def _update_metric_histories(self, risk_metrics: RiskMetrics, timestamp: float):
        """Update history of all metrics"""
        self.ha_history.add_value(risk_metrics.hallucination_number, timestamp)
        self.defect_history.add_value(risk_metrics.rho_def_mean, timestamp)
        self.coherence_global_history.add_value(risk_metrics.coherence_global, timestamp)
        self.coherence_modular_history.add_value(risk_metrics.coherence_modular, timestamp)

    def _assess_hallucination_risk(self, ha_value: float) -> RiskLevel:
        """Assess risk based on hallucination number"""
        return self._assess_metric_with_hysteresis(
            ha_value,
            self.thresholds.ha_warning,
            self.thresholds.ha_critical,
            self.thresholds.ha_emergency,
            increasing_is_bad=True,
        )

    def _assess_defect_risk(self, defect_density: float) -> RiskLevel:
        """Assess risk based on defect density"""
        return self._assess_metric_with_hysteresis(
            defect_density,
            self.thresholds.defect_warning,
            self.thresholds.defect_critical,
            self.thresholds.defect_emergency,
            increasing_is_bad=True,
        )

    def _assess_coherence_global_risk(self, coherence: float) -> RiskLevel:
        """Assess risk based on global coherence"""
        return self._assess_metric_with_hysteresis(
            coherence,
            self.thresholds.coherence_global_warning,
            self.thresholds.coherence_global_critical,
            self.thresholds.coherence_global_emergency,
            increasing_is_bad=False,  # –ù–∏–∑–∫–∞—è coherence = –ø–ª–æ—Ö–æ
        )

    def _assess_coherence_modular_risk(self, coherence: float) -> RiskLevel:
        """Assess risk based on modular coherence"""
        return self._assess_metric_with_hysteresis(
            coherence,
            self.thresholds.coherence_modular_warning,
            self.thresholds.coherence_modular_critical,
            self.thresholds.coherence_modular_emergency,
            increasing_is_bad=False,  # –ù–∏–∑–∫–∞—è coherence = –ø–ª–æ—Ö–æ
        )

    def _assess_metric_with_hysteresis(
        self,
        value: float,
        warning_threshold: float,
        critical_threshold: float,
        emergency_threshold: float,
        increasing_is_bad: bool = True,
    ) -> RiskLevel:
        """
        –û—Ü–µ–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É —Å —É—á–µ—Ç–æ–º –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—Ä–µ–±–µ–∑–≥–∞

        Args:
            value: –¢–µ–∫—É—â–µ–µ value –º–µ—Ç—Ä–∏–∫–∏
            warning_threshold: –ü–æ—Ä–æ–≥ WARNING
            critical_threshold: –ü–æ—Ä–æ–≥ CRITICAL
            emergency_threshold: –ü–æ—Ä–æ–≥ EMERGENCY
            increasing_is_bad: True –µ—Å–ª–∏ —Ä–æ—Å—Ç –º–µ—Ç—Ä–∏–∫–∏ = —É—Ö—É–¥—à–µ–Ω–∏–µ
        """

        if increasing_is_bad:
            # –î–ª—è –º–µ—Ç—Ä–∏–∫ –≥–¥–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ = –ø–ª–æ—Ö–æ (Ha, defects)
            if value >= emergency_threshold:
                return RiskLevel.EMERGENCY
            elif value >= critical_threshold:
                return RiskLevel.CRITICAL
            elif value >= warning_threshold:
                return RiskLevel.WARNING
            else:
                # Check –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–∞ –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏–π —Ä–∏—Å–∫–∞
                if self.current_risk_level == RiskLevel.EMERGENCY:
                    exit_threshold = emergency_threshold * self.thresholds.emergency_exit_factor
                    return RiskLevel.EMERGENCY if value > exit_threshold else RiskLevel.CRITICAL
                elif self.current_risk_level == RiskLevel.CRITICAL:
                    exit_threshold = critical_threshold * self.thresholds.critical_exit_factor
                    return RiskLevel.CRITICAL if value > exit_threshold else RiskLevel.WARNING
                elif self.current_risk_level == RiskLevel.WARNING:
                    exit_threshold = warning_threshold * self.thresholds.warning_exit_factor
                    return RiskLevel.WARNING if value > exit_threshold else RiskLevel.NORMAL
                else:
                    return RiskLevel.NORMAL
        else:
            # –î–ª—è –º–µ—Ç—Ä–∏–∫ –≥–¥–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ = –ø–ª–æ—Ö–æ (coherence)
            if value <= emergency_threshold:
                return RiskLevel.EMERGENCY
            elif value <= critical_threshold:
                return RiskLevel.CRITICAL
            elif value <= warning_threshold:
                return RiskLevel.WARNING
            else:
                # Check –≥–∏—Å—Ç–µ—Ä–µ–∑–∏—Å–∞ –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏–π —Ä–∏—Å–∫–∞
                if self.current_risk_level == RiskLevel.EMERGENCY:
                    exit_threshold = emergency_threshold / self.thresholds.emergency_exit_factor
                    return RiskLevel.EMERGENCY if value < exit_threshold else RiskLevel.CRITICAL
                elif self.current_risk_level == RiskLevel.CRITICAL:
                    exit_threshold = critical_threshold / self.thresholds.critical_exit_factor
                    return RiskLevel.CRITICAL if value < exit_threshold else RiskLevel.WARNING
                elif self.current_risk_level == RiskLevel.WARNING:
                    exit_threshold = warning_threshold / self.thresholds.warning_exit_factor
                    return RiskLevel.WARNING if value < exit_threshold else RiskLevel.NORMAL
                else:
                    return RiskLevel.NORMAL

    def _detect_anomalies(self, risk_metrics: RiskMetrics) -> List[str]:
        """Anomaly detection in metrics"""
        anomalies = []

        try:
            # Check –∞–Ω–æ–º–∞–ª–∏–π –ø–æ –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–µ
            if self.ha_history.is_anomaly(risk_metrics.hallucination_number):
                anomalies.append("Ha_anomaly")

            if self.defect_history.is_anomaly(risk_metrics.rho_def_mean):
                anomalies.append("Defects_anomaly")

            if self.coherence_global_history.is_anomaly(risk_metrics.coherence_global):
                anomalies.append("Coherence_global_anomaly")

            if self.coherence_modular_history.is_anomaly(risk_metrics.coherence_modular):
                anomalies.append("Coherence_modular_anomaly")

            # Update —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if anomalies:
                self.stats["anomalies_detected"] += len(anomalies)
                self.logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∞–Ω–æ–º–∞–ª–∏–∏: {', '.join(anomalies)}")

        except Exception as e:
            self.logger.error(f"Error –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π: {e}")

        return anomalies

    def _apply_escalation_logic(
        self, base_level: RiskLevel, assessment: RiskAssessment
    ) -> RiskLevel:
        """Apply escalation logic based on trends and violations"""

        # Check –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        negative_trends = [
            assessment.ha_trend == TrendDirection.INCREASING,
            assessment.defect_trend == TrendDirection.INCREASING,
            assessment.coherence_global_trend == TrendDirection.DECREASING,
            assessment.coherence_modular_trend == TrendDirection.DECREASING,
        ]

        negative_trend_count = sum(negative_trends)

        # –≠—Å–∫–∞–ª–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤
        if negative_trend_count >= 3:  # 3+ –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–∞
            if base_level == RiskLevel.WARNING:
                return RiskLevel.CRITICAL
            elif base_level == RiskLevel.CRITICAL:
                return RiskLevel.EMERGENCY
        elif negative_trend_count >= 2:  # 2 –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–∞
            if base_level == RiskLevel.NORMAL:
                return RiskLevel.WARNING

        # –≠—Å–∫–∞–ª–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π
        if self.consecutive_violations >= self.thresholds.violations_emergency_threshold:
            return RiskLevel.EMERGENCY
        elif self.consecutive_violations >= self.thresholds.violations_critical_threshold:
            return max(base_level, RiskLevel.CRITICAL, key=lambda x: x.value)
        elif self.consecutive_violations >= self.thresholds.violations_warning_threshold:
            return max(base_level, RiskLevel.WARNING, key=lambda x: x.value)

        return base_level

    def _update_violation_counters(self, assessment: RiskAssessment) -> int:
        """Update violation counters"""
        current_time = time.time()

        # –°—á–∏—Ç–∞–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –ª—é–±–æ–µ state –≤—ã—à–µ NORMAL
        if assessment.current_level != RiskLevel.NORMAL:
            self.total_violations += 1
            self.consecutive_violations += 1
        else:
            # –°–±—Ä–æ—Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞—Ä—É—à–µ–Ω–∏–π –ø—Ä–∏ –≤–æ–∑–≤—Ä–∞—Ç–µ –∫ –Ω–æ—Ä–º–µ
            if self.consecutive_violations > 0:
                self.logger.info(
                    f"System –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ {self.consecutive_violations} –Ω–∞—Ä—É—à–µ–Ω–∏–π"
                )
            self.consecutive_violations = 0

        # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ —Ä–∞–∑ –≤ hour
        if current_time - self.last_violation_reset > 3600:
            self.total_violations = 0
            self.last_violation_reset = current_time

        return self.total_violations

    def _calculate_systemic_risk(
        self, risk_metrics: RiskMetrics, assessment: RiskAssessment
    ) -> float:
        """Calculate integral systemic risk assessment [0.0 - 1.0]"""

        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–∏—Å–∫–∞
        weights = {
            "ha": 0.3,
            "defects": 0.25,
            "coherence_global": 0.2,
            "coherence_modular": 0.15,
            "trends": 0.05,
            "anomalies": 0.05,
        }

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫ [0, 1]
        ha_normalized = min(risk_metrics.hallucination_number / 1.0, 1.0)
        defects_normalized = min(risk_metrics.rho_def_mean / 0.5, 1.0)
        coherence_global_normalized = max(1.0 - risk_metrics.coherence_global, 0.0)
        coherence_modular_normalized = max(1.0 - risk_metrics.coherence_modular, 0.0)

        # –û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        trend_risk = 0.0
        if assessment.ha_trend == TrendDirection.INCREASING:
            trend_risk += 0.25
        if assessment.defect_trend == TrendDirection.INCREASING:
            trend_risk += 0.25
        if assessment.coherence_global_trend == TrendDirection.DECREASING:
            trend_risk += 0.25
        if assessment.coherence_modular_trend == TrendDirection.DECREASING:
            trend_risk += 0.25

        # –û—Ü–µ–Ω–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π
        anomaly_risk = min(len(assessment.anomalies_detected) / 4.0, 1.0)

        # –ò–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        systemic_risk = (
            weights["ha"] * ha_normalized
            + weights["defects"] * defects_normalized
            + weights["coherence_global"] * coherence_global_normalized
            + weights["coherence_modular"] * coherence_modular_normalized
            + weights["trends"] * trend_risk
            + weights["anomalies"] * anomaly_risk
        )

        return min(max(systemic_risk, 0.0), 1.0)

    def _identify_risk_factors(
        self, assessment: RiskAssessment, risk_metrics: RiskMetrics
    ) -> List[str]:
        """Identify active risk factors"""
        factors = []

        # –§–∞–∫—Ç–æ—Ä—ã –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
        if assessment.ha_risk != RiskLevel.NORMAL:
            factors.append(f"Ha={risk_metrics.hallucination_number:.3f}")

        if assessment.defect_risk != RiskLevel.NORMAL:
            factors.append(f"Defects={risk_metrics.rho_def_mean:.3f}")

        if assessment.coherence_global_risk != RiskLevel.NORMAL:
            factors.append(f"R_global={risk_metrics.coherence_global:.3f}")

        if assessment.coherence_modular_risk != RiskLevel.NORMAL:
            factors.append(f"R_modular={risk_metrics.coherence_modular:.3f}")

        # –§–∞–∫—Ç–æ—Ä—ã –ø–æ —Ç—Ä–µ–Ω–¥–∞–º
        if assessment.ha_trend == TrendDirection.INCREASING:
            factors.append("Ha_trending_up")
        if assessment.defect_trend == TrendDirection.INCREASING:
            factors.append("Defects_trending_up")
        if assessment.coherence_global_trend == TrendDirection.DECREASING:
            factors.append("R_global_trending_down")
        if assessment.coherence_modular_trend == TrendDirection.DECREASING:
            factors.append("R_modular_trending_down")

        # –§–∞–∫—Ç–æ—Ä—ã –ø–æ –∞–Ω–æ–º–∞–ª–∏—è–º
        factors.extend(assessment.anomalies_detected)

        # –§–∞–∫—Ç–æ—Ä—ã –ø–æ –Ω–∞—Ä—É—à–µ–Ω–∏—è–º
        if self.consecutive_violations > self.thresholds.violations_warning_threshold:
            factors.append(f"Violations={self.consecutive_violations}")

        return factors

    def _publish_assessment(self, assessment: RiskAssessment, risk_metrics: RiskMetrics):
        """Publish assessment to resonance bus"""
        try:
            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞
            publish_risk_metrics(
                hallucination_number=risk_metrics.hallucination_number,
                defect_density_mean=risk_metrics.rho_def_mean,
                risk_level=assessment.current_level.value,
                source_module="risk_monitor",
            )

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è
            detailed_payload = RiskMetricsPayload(
                source_module="risk_monitor",
                hallucination_number=risk_metrics.hallucination_number,
                defect_density_mean=risk_metrics.rho_def_mean,
                coherence_global=risk_metrics.coherence_global,
                coherence_modular=risk_metrics.coherence_modular,
                systemic_risk=assessment.systemic_risk_score,
                risk_level=assessment.current_level.value,
                risk_trend=assessment.ha_trend.value,  # –û—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–µ–Ω–¥
                violations_count=assessment.violations_count,
            )

            priority = EventPriority.NORMAL
            if assessment.current_level == RiskLevel.CRITICAL:
                priority = EventPriority.HIGH
            elif assessment.current_level == RiskLevel.EMERGENCY:
                priority = EventPriority.EMERGENCY

            self.bus.publish(TopicType.METRICS_RISK, detailed_payload, priority)

        except Exception as e:
            self.logger.error(f"Error –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤: {e}")

    def _trigger_emergency(self, assessment: RiskAssessment, risk_metrics: RiskMetrics):
        """Launch emergency protocols"""
        try:
            emergency_reason = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ state —Å–∏—Å—Ç–µ–º—ã: {assessment.get_risk_summary()}"

            publish_emergency(
                emergency_type="SYSTEMIC_RISK_CRITICAL",
                severity_level=5,
                trigger_reason=emergency_reason,
                source_module="risk_monitor",
            )

            self.logger.critical(
                f"üö® EMERGENCY TRIGGERED: {emergency_reason}\n"
                f"–°–∏—Å—Ç–µ–º–Ω—ã–π risk: {assessment.systemic_risk_score:.3f}\n"
                f"–§–∞–∫—Ç–æ—Ä—ã: {', '.join(assessment.risk_factors)}\n"
                f"Ha: {risk_metrics.hallucination_number:.4f}, "
                f"Defects: {risk_metrics.rho_def_mean:.4f}, "
                f"R_global: {risk_metrics.coherence_global:.4f}, "
                f"R_modular: {risk_metrics.coherence_modular:.4f}"
            )

        except Exception as e:
            self.logger.error(f"Error –∑–∞–ø—É—Å–∫–∞ –∞–≤–∞—Ä–∏–π–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")

    def get_current_status(self) -> Dict[str, Any]:
        """Get current risk monitor status"""
        with self._lock:
            status = {
                "current_risk_level": self.current_risk_level.value,
                "total_violations": self.total_violations,
                "consecutive_violations": self.consecutive_violations,
                "statistics": self.stats.copy(),
                "thresholds": {
                    "ha_emergency": self.thresholds.ha_emergency,
                    "defect_emergency": self.thresholds.defect_emergency,
                    "coherence_global_emergency": self.thresholds.coherence_global_emergency,
                    "coherence_modular_emergency": self.thresholds.coherence_modular_emergency,
                },
            }

            if self.last_assessment:
                status["last_assessment"] = {
                    "level": self.last_assessment.current_level.value,
                    "systemic_risk": self.last_assessment.systemic_risk_score,
                    "risk_factors": self.last_assessment.risk_factors,
                    "anomalies": self.last_assessment.anomalies_detected,
                    "time": self.last_assessment.assessment_time,
                }

            return status

    def update_thresholds(self, new_thresholds: RiskThresholds):
        """Update risk thresholds"""
        with self._lock:
            old_thresholds = self.thresholds
            self.thresholds = new_thresholds

            self.logger.info(f"–ü–æ—Ä–æ–≥–∏ —Ä–∏—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞

    def reset_violation_counters(self):
        """Reset violation counters"""
        with self._lock:
            self.total_violations = 0
            self.consecutive_violations = 0
            self.last_violation_reset = time.time()

            self.logger.info("–°—á–µ—Ç—á–∏–∫–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π —Å–±—Ä–æ—à–µ–Ω—ã")

    def get_metric_histories(self) -> Dict[str, List[float]]:
        """Get history of all metrics for analysis"""
        return {
            "ha_values": list(self.ha_history.values),
            "defect_values": list(self.defect_history.values),
            "coherence_global_values": list(self.coherence_global_history.values),
            "coherence_modular_values": list(self.coherence_modular_history.values),
            "timestamps": list(self.ha_history.timestamps),
        }

    def __repr__(self) -> str:
        """String representation of monitor"""
        return (
            f"RiskMonitor(level={self.current_risk_level.value}, "
            f"violations={self.consecutive_violations}, "
            f"assessments={self.stats['assessments_count']})"
        )


# –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def create_default_risk_monitor(**kwargs) -> RiskMonitor:
    """Create risk monitor with default settings"""
    return RiskMonitor(**kwargs)


def create_strict_risk_monitor() -> RiskMonitor:
    """Create strict risk monitor with low thresholds"""
    strict_thresholds = RiskThresholds(
        ha_warning=0.4,
        ha_critical=0.6,
        ha_emergency=0.8,
        defect_warning=0.03,
        defect_critical=0.07,
        defect_emergency=0.15,
        coherence_global_warning=0.5,
        coherence_global_critical=0.4,
        coherence_global_emergency=0.3,
        coherence_modular_warning=0.6,
        coherence_modular_critical=0.4,
        coherence_modular_emergency=0.3,
    )

    return RiskMonitor(thresholds=strict_thresholds)


def create_relaxed_risk_monitor() -> RiskMonitor:
    """Create lenient risk monitor with high thresholds"""
    relaxed_thresholds = RiskThresholds(
        ha_warning=0.8,
        ha_critical=0.9,
        ha_emergency=0.99,
        defect_warning=0.1,
        defect_critical=0.2,
        defect_emergency=0.4,
        coherence_global_warning=0.3,
        coherence_global_critical=0.2,
        coherence_global_emergency=0.1,
        coherence_modular_warning=0.4,
        coherence_modular_critical=0.2,
        coherence_modular_emergency=0.1,
    )

    return RiskMonitor(thresholds=relaxed_thresholds)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    import asyncio
    from ..orchestrator.resonance_bus import initialize_global_bus

    async def demo_risk_monitor():
        # Initialization —à–∏–Ω—ã
        await initialize_global_bus()

        # Creation –º–æ–Ω–∏—Ç–æ—Ä–∞
        monitor = create_default_risk_monitor()

        # Creation —Ç–µ—Å—Ç–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        from ..core.state import RiskMetrics
        import numpy as np

        # –°–∏–º—É–ª—è—Ü–∏—è –Ω–∞—Ä–∞—Å—Ç–∞—é—â–µ–≥–æ —Ä–∏—Å–∫–∞
        for step in range(20):
            # –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É—Ö—É–¥—à–∞—é—â–∏–µ—Å—è –º–µ—Ç—Ä–∏–∫–∏
            test_metrics = RiskMetrics(
                rho_def_field=np.zeros((10, 10)),
                rho_def_mean=0.02 + step * 0.01,
                hallucination_number=0.3 + step * 0.04,
                systemic_risk=0.1 + step * 0.03,
                coherence_global=0.8 - step * 0.03,
                coherence_modular=0.7 - step * 0.025,
            )

            # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤
            assessment = monitor.assess_risks(test_metrics)

            print(
                f"–®–∞–≥ {step}: {assessment.current_level.value} "
                f"(risk: {assessment.systemic_risk_score:.3f}) - "
                f"{assessment.get_risk_summary()}"
            )

            # Pause
            await asyncio.sleep(0.1)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        status = monitor.get_current_status()
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {status['statistics']}")

    # Start –¥–µ–º–æ
    if __name__ == "__main__":
        asyncio.run(demo_risk_monitor())
